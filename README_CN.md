[English](README.md) | [ä¸­æ–‡](README_CN.md)

# âœ¨ Tiny Qwen

ä¸€ä¸ªç®€æ´æ˜“è¯»çš„ PyTorch ä»£ç åº“ï¼Œç”¨äºé‡æ–°å®ç° Qwen2 å’Œ Qwen2.5ï¼ˆå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼‰ã€‚

å¦‚æœä½ è§‰å¾— [Transformers](https://github.com/huggingface/transformers) ä»£ç å¤ªåºå¤§éš¾è¯»ï¼Œé‚£ä¹ˆè¿™ä¸ªä»“åº“å¯èƒ½æ›´é€‚åˆä½ ï¼çµæ„Ÿæ¥æºäº [nanoGPT](https://github.com/karpathy/nanoGPT) å’Œ [litGPT](https://github.com/Lightning-AI/litgpt)ï¼Œå¯åŒæ—¶æ”¯æŒçº¯æ–‡æœ¬æ¨¡å‹ï¼ˆå¦‚ Instructã€Coderã€Math ç­‰ï¼‰ä»¥åŠæ–‡æœ¬ + å›¾åƒï¼ˆVLï¼‰ã€‚è¿˜æ”¯æŒä»»ä½•å…¨ç²¾åº¦çš„ Qwen2+ æ¨¡å‹ï¼Œå°ºå¯¸ä¸é™ã€‚åªéœ€ä» [Hugging Face](https://huggingface.co/Qwen) é€‰æ‹©ä¸€ä¸ª repo id å³å¯ã€‚

æ³¨æ„ï¼šå¤§äº 32B çš„æ¨¡å‹é€šå¸¸éœ€è¦å¤šå— GPUã€‚æˆ‘ä»¬ä¼šåœ¨ä»ŠååŠ å…¥ FSDP æ”¯æŒã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·éšæ—¶æ Issue æˆ–æäº¤ PRã€‚

æ­¤å¤–ï¼Œæˆ‘åœ¨æ‰¾å¿—åŒé“åˆçš„äººåˆä¼™ä¸€èµ·æ„å»ºè§†è§‰ AI Agentã€‚å¦‚æœä½ å¯¹æ­¤æ„Ÿå…´è¶£ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ğŸ¤—~ (æˆ‘çš„ä¸»é¡µåœ¨ [è¿™é‡Œ](https://github.com/Emericen))

---

## ğŸ¦‹ å¿«é€Ÿå¼€å§‹

æ¨èå…ˆå®‰è£…å¸¦ CUDA çš„ PyTorchï¼ˆè§ [å®˜æ–¹æ–‡æ¡£](https://pytorch.org/get-started/locally/)ï¼‰ã€‚ç„¶åï¼š

```bash
pip install -r requirements.txt
```

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from models.model import Qwen2, Qwen2VL
from models.processor import Processor
from PIL import Image

# çº¯æ–‡æœ¬æ¨¡å‹
model_name = "Qwen/Qwen2.5-3B"
model = Qwen2.from_pretrained(repo_id=model_name, device="cuda")
processor = Processor(repo_id=model_name)

context = [
    "<|im_start|>user\nwhat is the meaning of life?<|im_end|>\n<|im_start|>assistant\n"
]
inputs = processor(context, device="cuda")
output = model.generate(input_ids=inputs["input_ids"], max_new_tokens=64)
output_text = processor.tokenizer.decode(output[0].tolist())

# æ–‡æœ¬ + å›¾åƒæ¨¡å‹
model_name = "Qwen/Qwen2-VL-2B-Instruct"
model = Qwen2VL.from_pretrained(repo_id=model_name, device="cuda")
processor = Processor(
    repo_id=model_name,
    vision_config=model.config.vision_config,
)

context = [
    "<|im_start|>user\n<|vision_start|>",
    Image.open("images/test-image.jpeg"),
    "<|vision_end|>What's on this image?<|im_end|>\n<|im_start|>assistant\n",
]
inputs = processor(context, device="cuda")
output = model.generate(
    input_ids=inputs["input_ids"],
    pixels=inputs["pixels"],
    d_image=inputs["d_image"],
    max_new_tokens=64,
)
output_text = processor.tokenizer.decode(output[0].tolist())
```

---

## ğŸ› ï¸ å¾®è°ƒ / è‡ªå®šä¹‰è®­ç»ƒ

æŸ¥çœ‹ `train/train_sft.py` ä»¥äº†è§£å¦‚ä½•ç®€å•åœ°å¯¹ Qwen æ¨¡å‹è¿›è¡Œ SFTï¼ˆæœ‰ç›‘ç£å¾®è°ƒï¼‰ã€‚ä»»æ„å…¼å®¹ `torch.nn.Module` çš„åº“éƒ½è¡Œï¼Œæ­¤å¤„æˆ‘ç”¨ [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/index.html) æ¥åšè®­ç»ƒã€‚ä¹Ÿå¯ä»¥å‚è§ `train/train_mnist.py` ä»¥è·å–æ€è·¯ã€‚

è¿è¡Œç¤ºä¾‹ï¼š

```bash
PYTHONPATH=. python train/train_mnist.py
```

æˆ–

```bash
PYTHONPATH=. python train/train_sft.py
```
